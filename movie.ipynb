{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: moviepy in c:\\users\\redan\\.conda\\envs\\redbaseenv\\lib\\site-packages (1.0.3)\n",
      "Requirement already satisfied: SpeechRecognition in c:\\users\\redan\\.conda\\envs\\redbaseenv\\lib\\site-packages (3.10.1)\n",
      "Requirement already satisfied: pydub in c:\\users\\redan\\.conda\\envs\\redbaseenv\\lib\\site-packages (0.25.1)\n",
      "Requirement already satisfied: decorator<5.0,>=4.0.2 in c:\\users\\redan\\.conda\\envs\\redbaseenv\\lib\\site-packages (from moviepy) (4.4.2)\n",
      "Requirement already satisfied: tqdm<5.0,>=4.11.2 in c:\\users\\redan\\.conda\\envs\\redbaseenv\\lib\\site-packages (from moviepy) (4.65.0)\n",
      "Requirement already satisfied: requests<3.0,>=2.8.1 in c:\\users\\redan\\.conda\\envs\\redbaseenv\\lib\\site-packages (from moviepy) (2.31.0)\n",
      "Requirement already satisfied: proglog<=1.0.0 in c:\\users\\redan\\.conda\\envs\\redbaseenv\\lib\\site-packages (from moviepy) (0.1.10)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\redan\\.conda\\envs\\redbaseenv\\lib\\site-packages (from moviepy) (1.26.4)\n",
      "Requirement already satisfied: imageio<3.0,>=2.5 in c:\\users\\redan\\.conda\\envs\\redbaseenv\\lib\\site-packages (from moviepy) (2.34.0)\n",
      "Requirement already satisfied: imageio-ffmpeg>=0.2.0 in c:\\users\\redan\\.conda\\envs\\redbaseenv\\lib\\site-packages (from moviepy) (0.4.9)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\redan\\.conda\\envs\\redbaseenv\\lib\\site-packages (from SpeechRecognition) (4.9.0)\n",
      "Requirement already satisfied: pillow>=8.3.2 in c:\\users\\redan\\.conda\\envs\\redbaseenv\\lib\\site-packages (from imageio<3.0,>=2.5->moviepy) (10.2.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\redan\\.conda\\envs\\redbaseenv\\lib\\site-packages (from imageio-ffmpeg>=0.2.0->moviepy) (68.2.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\redan\\.conda\\envs\\redbaseenv\\lib\\site-packages (from requests<3.0,>=2.8.1->moviepy) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\redan\\.conda\\envs\\redbaseenv\\lib\\site-packages (from requests<3.0,>=2.8.1->moviepy) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\redan\\.conda\\envs\\redbaseenv\\lib\\site-packages (from requests<3.0,>=2.8.1->moviepy) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\redan\\.conda\\envs\\redbaseenv\\lib\\site-packages (from requests<3.0,>=2.8.1->moviepy) (2024.2.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\redan\\.conda\\envs\\redbaseenv\\lib\\site-packages (from tqdm<5.0,>=4.11.2->moviepy) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install moviepy SpeechRecognition pydub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-14 18:37:48 - INFO - Processing video: SmallTalk.mp4\n",
      "2024-03-14 18:38:07 - WARNING - Google Speech Recognition could not understand audio SmallTalk_chunk4.wav.\n",
      "2024-03-14 18:38:07 - WARNING - Google Speech Recognition could not understand audio SmallTalk_chunk5.wav.\n",
      "2024-03-14 18:38:08 - WARNING - Google Speech Recognition could not understand audio SmallTalk_chunk7.wav.\n",
      "2024-03-14 18:38:08 - WARNING - Google Speech Recognition could not understand audio SmallTalk_chunk9.wav.\n",
      "2024-03-14 18:38:09 - WARNING - Google Speech Recognition could not understand audio SmallTalk_chunk1.wav.\n",
      "2024-03-14 18:38:34 - INFO - Transcribed text has been saved to c:\\Users\\redan\\OneDrive\\Documents\\Git\\Pyxscribe\\transcripts\\audio_extract_1.txt\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "from pathlib import Path\n",
    "from moviepy.editor import VideoFileClip\n",
    "import speech_recognition as sr\n",
    "from pydub import AudioSegment\n",
    "from pydub.silence import split_on_silence\n",
    "import concurrent.futures\n",
    "import shutil\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s', datefmt='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "# Paths and directory names\n",
    "current_directory = Path.cwd()\n",
    "videos_dir_name = 'videos'\n",
    "transcripts_dir_name = 'transcripts'\n",
    "chunks_dir_name = 'audio_chunks'\n",
    "processed_videos_file_name = 'processed_videos.txt'\n",
    "\n",
    "# Directories\n",
    "videos_dir_path = current_directory / videos_dir_name\n",
    "transcripts_dir_path = current_directory / transcripts_dir_name\n",
    "chunks_dir_path = current_directory / chunks_dir_name\n",
    "processed_videos_path = current_directory / processed_videos_file_name\n",
    "\n",
    "# Ensure directories exist\n",
    "transcripts_dir_path.mkdir(exist_ok=True)\n",
    "chunks_dir_path.mkdir(exist_ok=True)\n",
    "\n",
    "# Create or append to the processed videos file\n",
    "processed_videos_path.touch()\n",
    "\n",
    "def get_processed_videos():\n",
    "    \"\"\"Read the list of already processed videos.\"\"\"\n",
    "    with processed_videos_path.open('r') as file:\n",
    "        return set(file.read().splitlines())\n",
    "\n",
    "def mark_video_as_processed(video_name):\n",
    "    \"\"\"Mark a video as processed by adding it to the list.\"\"\"\n",
    "    with processed_videos_path.open('a') as file:\n",
    "        file.write(f\"{video_name}\\n\")\n",
    "\n",
    "def get_next_file_id(directory_path: Path, prefix='audio_extract_'):\n",
    "    \"\"\"Get the next file ID for naming output files.\"\"\"\n",
    "    existing_files = [f.stem for f in directory_path.glob(f'{prefix}*.txt')]\n",
    "    existing_ids = [int(f.replace(prefix, '')) for f in existing_files if f.replace(prefix, '').isdigit()]\n",
    "    next_id = max(existing_ids) + 1 if existing_ids else 1\n",
    "    return next_id\n",
    "\n",
    "def get_filenames(directory_path: Path, processed_videos):\n",
    "    \"\"\"Filter out already processed videos.\"\"\"\n",
    "    if directory_path.exists() and directory_path.is_dir():\n",
    "        return [entry for entry in directory_path.iterdir() if entry.is_file() and entry.suffix == '.mp4' and entry.name not in processed_videos]\n",
    "    logging.error(f\"Directory '{directory_path}' does not exist.\")\n",
    "    return []\n",
    "\n",
    "def segment_audio(video_file):\n",
    "    video_clip = VideoFileClip(str(video_file))\n",
    "    audio_file = chunks_dir_path / (video_file.stem + '.wav')\n",
    "    video_clip.audio.write_audiofile(str(audio_file), logger=None)  # Disable moviepy logging\n",
    "    \n",
    "    sound = AudioSegment.from_file(str(audio_file))\n",
    "    chunks = split_on_silence(sound, min_silence_len=1000, silence_thresh=sound.dBFS-14, keep_silence=500)\n",
    "    chunk_files = []\n",
    "    for i, chunk in enumerate(chunks, start=1):\n",
    "        chunk_file = chunks_dir_path / f\"{audio_file.stem}_chunk{i}.wav\"\n",
    "        chunk.export(chunk_file, format=\"wav\")\n",
    "        chunk_files.append(chunk_file)\n",
    "    \n",
    "    # Make sure to return exactly two items: the list of chunk files and the audio file stem\n",
    "    return chunk_files, audio_file.stem\n",
    "\n",
    "def transcribe_audio_chunk(chunk_file: Path) -> str:\n",
    "    \"\"\"Transcribe a single chunk of audio to text.\"\"\"\n",
    "    recognizer = sr.Recognizer()\n",
    "    with sr.AudioFile(str(chunk_file)) as source:\n",
    "        audio_data = recognizer.record(source)\n",
    "        try:\n",
    "            return recognizer.recognize_google(audio_data)\n",
    "        except sr.UnknownValueError:\n",
    "            logging.warning(f\"Google Speech Recognition could not understand audio {chunk_file.name}.\")\n",
    "        except sr.RequestError as e:\n",
    "            logging.error(f\"Could not request results from Google Speech Recognition service; {e}.\")\n",
    "    return \"\"\n",
    "\n",
    "def clean_up_chunks(chunk_files):\n",
    "    \"\"\"Remove chunk files after processing.\"\"\"\n",
    "    for chunk_file in chunk_files:\n",
    "        chunk_file.unlink()\n",
    "\n",
    "def transcribe_video(video_file: Path, processed_videos):\n",
    "    \"\"\"Include a check to skip already processed videos.\"\"\"\n",
    "    if video_file.name in processed_videos:\n",
    "        logging.info(f\"Skipping {video_file.name}, already processed.\")\n",
    "        return\n",
    "    \n",
    "    logging.info(f\"Processing video: {video_file.name}\")\n",
    "    chunk_files, stem = segment_audio(video_file)\n",
    "    all_text = []\n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        futures = {executor.submit(transcribe_audio_chunk, chunk_file): chunk_file for chunk_file in chunk_files}\n",
    "        for future in concurrent.futures.as_completed(futures):\n",
    "            chunk_file = futures[future]\n",
    "            try:\n",
    "                text = future.result()\n",
    "                if text:\n",
    "                    all_text.append(text)\n",
    "            except Exception as exc:\n",
    "                logging.error(f\"{chunk_file.name} generated an exception: {exc}\")\n",
    "    \n",
    "    clean_up_chunks(chunk_files)  # Clean up after transcription\n",
    "    \n",
    "    if all_text:\n",
    "        extracted_text = \"\\n\".join(all_text)\n",
    "        next_id = get_next_file_id(transcripts_dir_path)\n",
    "        output_file_name = f\"audio_extract_{next_id}.txt\"\n",
    "        output_file = transcripts_dir_path / output_file_name\n",
    "        output_file.write_text(extracted_text)\n",
    "        mark_video_as_processed(video_file.name)\n",
    "        logging.info(f\"Transcribed text has been saved to {output_file}\")\n",
    "\n",
    "def main():\n",
    "    processed_videos = get_processed_videos()\n",
    "    video_files = get_filenames(videos_dir_path, processed_videos)\n",
    "    for video_file in video_files:\n",
    "        transcribe_video(video_file, processed_videos)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "REDBaseEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
